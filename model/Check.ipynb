{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import imp\n",
    "\n",
    "def change_data(data, Flag_y = True ):\n",
    "    \n",
    "    if (Flag_y ==True):\n",
    "    \n",
    "        categorical = ['top_left_square', 'top_middle_square', 'top_right_square','middle_left_square',\\\n",
    "             'middle_middle_square', 'middle_right_square','bottom_left_square', 'bottom_middle_square', 'bottom_right_square']\n",
    "        X = data[categorical]\n",
    "        X_new = pd.get_dummies(X)\n",
    "        lb_make = LabelEncoder()\n",
    "        data.drop(categorical,inplace=True,axis=1)\n",
    "        data[\"class\"] = lb_make.fit_transform(data[\"class\"])\n",
    "        data.reset_index(drop = True, inplace= True)\n",
    "        X_new.reset_index(drop = True, inplace= True)\n",
    "        bigdata= bigdata = pd.concat([X_new, data], axis= 1)\n",
    "        return bigdata\n",
    "    else:\n",
    "        categorical = ['top_left_square', 'top_middle_square', 'top_right_square','middle_left_square',\\\n",
    "             'middle_middle_square', 'middle_right_square','bottom_left_square', 'bottom_middle_square', 'bottom_right_square']\n",
    "        X = data[categorical]\n",
    "        data.drop(categorical,inplace=True,axis=1)\n",
    "        X_new = pd.get_dummies(X)\n",
    "        return X_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "Successfully installed joblib-0.14.1\n"
     ]
    }
   ],
   "source": [
    "! pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import dump,load\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "def save_models(model_name, file):\n",
    "   dump(model_name,\"./{}\".format(file))\n",
    "\n",
    "\n",
    "def knn_model(feature, target):\n",
    "    #training with train test score \n",
    "    knn = KNeighborsClassifier()\n",
    "    ##grid search cross -fold\n",
    "    knn_params = {\"n_neighbors\":np.arange(1,25)}\n",
    "    knn_gscv = GridSearchCV(knn, knn_params,cv=10)\n",
    "    knn_gscv.fit(feature,target.values.ravel())\n",
    "    print(knn_gscv.best_params_)\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    save_models(knn_gscv,\"knn_model.joblib\")\n",
    "\n",
    "def random_forest(feature, target):\n",
    "    clf = RandomForestClassifier(random_state = 42 )\n",
    "    #clf = clf.fit(feature,target)\n",
    "    parameter_grid = {'max_depth': [1, 2, 3, 4, 5, 6,7,8 ,9 ,10],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "    clf = GridSearchCV(clf,parameter_grid,cv=10)\n",
    "    clf =clf.fit(feature,target.values.ravel())\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "\n",
    "    save_models(clf,\"random_forest.joblib\")\n",
    "\n",
    "def predict_using_model(x,y,filename= \"./knn_model.joblib\"):\n",
    "\n",
    "    \n",
    "    model = load(filename)\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    matrix = confusion_matrix(y , y_pred)\n",
    "    print({\n",
    "        \"accuracy\": float((matrix[0][0]+matrix[1][1])/(sum(matrix[0])+sum(matrix[1]))),\n",
    "        \"no_correct\" : int(matrix[0][0]),\n",
    "        \"no_incorrect\" : int(matrix[0][1]),\n",
    "        \"yes_correct\" : int(matrix[1][1]),\n",
    "        \"yes_incorrect\" : int(matrix[1][0])\n",
    "        })\n",
    "\n",
    "def probability_predict(x,filename = './knn_model.joblib'):\n",
    "    #fi = os.getcwd()+'/model/'+filename\n",
    "    fi = filename\n",
    "    #change null to b \n",
    "    x.replace(\"null\",\"b\",inplace=True)\n",
    "    x = x.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "    #change missing columns with 0 \n",
    "    cls_group = ['top_left_square_b', 'top_left_square_o', 'top_left_square_x',\n",
    "       'top_middle_square_b', 'top_middle_square_o', 'top_middle_square_x',\n",
    "       'top_right_square_b', 'top_right_square_o', 'top_right_square_x',\n",
    "       'middle_left_square_b', 'middle_left_square_o', 'middle_left_square_x',\n",
    "       'middle_middle_square_b', 'middle_middle_square_o',\n",
    "       'middle_middle_square_x', 'middle_right_square_b',\n",
    "       'middle_right_square_o', 'middle_right_square_x',\n",
    "       'bottom_left_square_b', 'bottom_left_square_o', 'bottom_left_square_x',\n",
    "       'bottom_middle_square_b', 'bottom_middle_square_o',\n",
    "       'bottom_middle_square_x', 'bottom_right_square_b',\n",
    "       'bottom_right_square_o', 'bottom_right_square_x']\n",
    "    \n",
    "    data =  change_data(x,False)\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "    \n",
    "    for i in cls_group:\n",
    "        if i not in data.columns:\n",
    "            new_data[i]=0\n",
    "        else:\n",
    "            new_data[i] = data[i]\n",
    "    \n",
    "    model = load(fi)\n",
    "    new_data = np.nan_to_num(new_data)\n",
    "    print(new_data)\n",
    "    probab = model.predict_proba(new_data)\n",
    "\n",
    "    return ({\n",
    "        \"x\": probab[0][0],\n",
    "        \"o\": probab[0][1],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 4}\n",
      "0.917910447761194\n",
      "{'accuracy': 0.9166666666666666, 'no_correct': 81, 'no_incorrect': 14, 'yes_correct': 183, 'yes_incorrect': 10}\n",
      "{'n_neighbors': 12}\n",
      "0.9731343283582089\n",
      "{'accuracy': 0.9861111111111112, 'no_correct': 91, 'no_incorrect': 4, 'yes_correct': 193, 'yes_incorrect': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"./../data/model.csv\")\n",
    "    X, y = np.split(data, [-1], axis=1)\n",
    "    seed= 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = seed)   \n",
    "    #random forest \n",
    "    random_forest(X_train,y_train) \n",
    "    predict_using_model(X_test,y_test)\n",
    "    knn_model(X_train,y_train)\n",
    "    predict_using_model(X_test,y_test,\"./knn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 0.3333333333333333, 'o': 0.6666666666666666}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[['null','null','X','null','O','null','null','null','null']]\n",
    "c = ['top_left_square', 'top_middle_square', 'top_right_square','middle_left_square','middle_middle_square', 'middle_right_square','bottom_left_square', 'bottom_middle_square', 'bottom_right_square']\n",
    "\n",
    "df = pd.DataFrame(a,columns=c)\n",
    "probability_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
